{"version":3,"file":"chunk-node_modules_codemirror_legacy-modes_mode_solr_js-xxxxxxxxxxxx.js","mappings":"2KAAA,IAAIA,EAAe,4CACfC,EAAiB,uBACjBC,EAAmB,qBAkDvB,SAASC,EAAUC,CAAM,CAAEC,CAAK,EAC9B,IApBiBC,EAoBbA,EAAKF,EAAOG,IAAI,GAQpB,MAPID,KAAAA,EACFD,EAAMG,QAAQ,CA9CT,SAASJ,CAAM,CAAEC,CAAK,EAE3B,IADA,IAAqBE,EAAjBE,EAAU,GAEZ,MADMF,CAAAA,EAAOH,EAAOG,IAAI,EAAC,GACrBA,CAAAA,GA2CuBD,GA3CLG,CAAM,GAC5BA,EAAU,CAACA,GAAWF,MAAAA,EAIxB,OADKE,GAASJ,CAAAA,EAAMG,QAAQ,CAAGL,CAAQ,EAChC,QACT,EAsCSF,EAAeS,IAAI,CAACJ,GAC3BD,EAAMG,QAAQ,CAnCT,SAASJ,CAAM,CAAEC,CAAK,EAO3B,MANIM,KAkC2BL,EAjC7BF,EAAOQ,GAAG,CAAC,MACQ,KAgCUN,GA/B7BF,EAAOQ,GAAG,CAAC,MAEbP,EAAMG,QAAQ,CAAGL,EACV,UACT,EA4BSH,EAAaU,IAAI,CAACJ,IACzBD,CAAAA,EAAMG,QAAQ,EA1BCF,EA0BYA,EAzBtB,SAASF,CAAM,CAAEC,CAAK,EAE3B,IADA,IA/BcQ,EA+BVA,EAAOP,EACJ,CAACA,EAAKF,EAAOU,IAAI,EAAC,GAAMR,MAAAA,EAAGS,KAAK,CAACf,IACtCa,GAAQT,EAAOG,IAAI,SAIrB,CADAF,EAAMG,QAAQ,CAAGL,EACbD,EAAiBQ,IAAI,CAACG,IACjB,WArCJG,WADSH,EAuCIA,GAtCII,QAAQ,KAAOJ,EAuC5B,SACAT,KAAAA,EAAOU,IAAI,GACX,eAEA,QACX,EAU+B,EAExB,EAAON,QAAQ,EAAIL,EAAaE,EAAMG,QAAQ,CAACJ,EAAQC,GAAS,IACzE,CAEO,IAAMa,EAAO,CAClBC,KAAM,OAENC,WAAY,WACV,MAAO,CACLZ,SAAUL,CACZ,CACF,EAEAkB,MAAO,SAASjB,CAAM,CAAEC,CAAK,SAC3B,EAAWiB,QAAQ,GAAW,KACvBjB,EAAMG,QAAQ,CAACJ,EAAQC,EAChC,CACF,C","sources":["node_modules/@codemirror/legacy-modes/mode/solr.js"],"sourcesContent":["var isStringChar = /[^\\s\\|\\!\\+\\-\\*\\?\\~\\^\\&\\:\\(\\)\\[\\]\\{\\}\\\"\\\\]/;\nvar isOperatorChar = /[\\|\\!\\+\\-\\*\\?\\~\\^\\&]/;\nvar isOperatorString = /^(OR|AND|NOT|TO)$/i;\n\nfunction isNumber(word) {\n  return parseFloat(word).toString() === word;\n}\n\nfunction tokenString(quote) {\n  return function(stream, state) {\n    var escaped = false, next;\n    while ((next = stream.next()) != null) {\n      if (next == quote && !escaped) break;\n      escaped = !escaped && next == \"\\\\\";\n    }\n\n    if (!escaped) state.tokenize = tokenBase;\n    return \"string\";\n  };\n}\n\nfunction tokenOperator(operator) {\n  return function(stream, state) {\n    if (operator == \"|\")\n      stream.eat(/\\|/);\n    else if (operator == \"&\")\n      stream.eat(/\\&/);\n\n    state.tokenize = tokenBase;\n    return \"operator\";\n  };\n}\n\nfunction tokenWord(ch) {\n  return function(stream, state) {\n    var word = ch;\n    while ((ch = stream.peek()) && ch.match(isStringChar) != null) {\n      word += stream.next();\n    }\n\n    state.tokenize = tokenBase;\n    if (isOperatorString.test(word))\n      return \"operator\";\n    else if (isNumber(word))\n      return \"number\";\n    else if (stream.peek() == \":\")\n      return \"propertyName\";\n    else\n      return \"string\";\n  };\n}\n\nfunction tokenBase(stream, state) {\n  var ch = stream.next();\n  if (ch == '\"')\n    state.tokenize = tokenString(ch);\n  else if (isOperatorChar.test(ch))\n    state.tokenize = tokenOperator(ch);\n  else if (isStringChar.test(ch))\n    state.tokenize = tokenWord(ch);\n\n  return (state.tokenize != tokenBase) ? state.tokenize(stream, state) : null;\n}\n\nexport const solr = {\n  name: \"solr\",\n\n  startState: function() {\n    return {\n      tokenize: tokenBase\n    };\n  },\n\n  token: function(stream, state) {\n    if (stream.eatSpace()) return null;\n    return state.tokenize(stream, state);\n  }\n};\n"],"names":["isStringChar","isOperatorChar","isOperatorString","tokenBase","stream","state","ch","next","tokenize","escaped","test","operator","eat","word","peek","match","parseFloat","toString","solr","name","startState","token","eatSpace"],"sourceRoot":""}